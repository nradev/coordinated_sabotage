{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee044e01-0449-496e-b00a-b51a9f29f5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import Literal, Type, TypeAlias\n",
    "\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d49b261-82a5-43bd-9089-a3d6fdad7ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"bigcode/bigcodebench\", split=\"v0.1.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8163b98-2087-4bd0-8d22-a3a9c64804a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb292421-1fd7-4af4-99c2-1755d9a66ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_id': 'BigCodeBench/95',\n",
       " 'complete_prompt': 'import pandas as pd\\nfrom random import randint, uniform, seed\\n\\ndef task_func(categories=None, months=None, random_seed=42):\\n    \"\"\"\\n    Generates a DataFrame with simulated monthly sales data for various product categories, ensuring reproducibility through the use of a random seed.\\n\\n    Parameters:\\n        categories (list of str, optional): A list specifying the product categories to include in the report. If not provided, defaults to [\\'Electronics\\', \\'Clothing\\', \\'Home & Kitchen\\', \\'Books\\', \\'Beauty & Personal Care\\'].\\n        months (list of str, optional): A list specifying the months to include in the report. If not provided, defaults to [\\'January\\', \\'February\\', \\'March\\', \\'April\\', \\'May\\', \\'June\\', \\'July\\', \\'August\\', \\'September\\', \\'October\\', \\'November\\', \\'December\\'].\\n        random_seed (int, optional): The seed value for the random number generator to ensure the reproducibility of the sales data. Defaults to 42.\\n\\n    Returns:\\n        pandas.DataFrame: A DataFrame with three columns: \\'Month\\', \\'Category\\', and \\'Sales\\'. The \\'Sales\\' values are floating-point numbers in the range [100, 501), generated by the formula: randint(100, 500) + uniform(0, 1), ensuring sales values are diverse yet consistent upon repeated executions with the same seed.\\n\\n    Raises:\\n        ValueError: If either \\'categories\\' or \\'months\\' is not provided as a list or if either is an empty list.\\n\\n    Notes:\\n        - The function sets the random seed at the beginning of execution to ensure that the generated sales data is the same for any given seed value.\\n        - The sales data for each category is generated for each month, creating a comprehensive report that spans all specified categories and months.\\n\\n    Requirements:\\n    - pandas \\n    - random\\n\\n    Example:\\n        >>> report = task_func()\\n        >>> print(report.head())\\n             Month                Category       Sales\\n        0  January             Electronics  427.111331\\n        1  January                Clothing  479.275029\\n        2  January          Home & Kitchen  214.139538\\n        3  January                   Books  152.676699\\n        4  January  Beauty & Personal Care  379.086939\\n    \"\"\"\\n',\n",
       " 'instruct_prompt': \"Generates a DataFrame with simulated monthly sales data for various product categories, ensuring reproducibility through the use of a random seed.\\nNote that: Notes: The function sets the random seed at the beginning of execution to ensure that the generated sales data is the same for any given seed value. The sales data for each category is generated for each month, creating a comprehensive report that spans all specified categories and months.\\nThe function should raise the exception for: ValueError: If either 'categories' or 'months' is not provided as a list or if either is an empty list.\\nThe function should output with:\\n    pandas.DataFrame: A DataFrame with three columns: 'Month', 'Category', and 'Sales'. The 'Sales' values are floating-point numbers in the range [100, 501), generated by the formula: randint(100, 500) + uniform(0, 1), ensuring sales values are diverse yet consistent upon repeated executions with the same seed.\\nYou should write self-contained code starting with:\\n```\\nimport pandas as pd\\nfrom random import randint, uniform, seed\\ndef task_func(categories=None, months=None, random_seed=42):\\n```\",\n",
       " 'canonical_solution': '\\n    if categories is None:\\n        categories = [\\'Electronics\\', \\'Clothing\\', \\'Home & Kitchen\\', \\'Books\\', \\'Beauty & Personal Care\\']\\n    if months is None:\\n        months = [\\'January\\', \\'February\\', \\'March\\', \\'April\\', \\'May\\', \\'June\\', \\'July\\', \\'August\\', \\'September\\', \\'October\\', \\'November\\', \\'December\\']\\n\\n    if not isinstance(categories, list) or not categories:\\n        raise ValueError(\"Invalid \\'categories\\': must be a non-empty list.\")\\n    if not isinstance(months, list) or not months:\\n        raise ValueError(\"Invalid \\'months\\': must be a non-empty list.\")\\n\\n    seed(random_seed)  # Setting the seed for reproducibility\\n    sales_data = []\\n\\n    for month in months:\\n        for category in categories:\\n            sales = randint(100, 500) + uniform(0, 1)\\n            sales_data.append([month, category, sales])\\n\\n    sales_df = pd.DataFrame(sales_data, columns=[\\'Month\\', \\'Category\\', \\'Sales\\'])\\n    return sales_df',\n",
       " 'code_prompt': 'import pandas as pd\\nfrom random import randint, uniform, seed\\ndef task_func(categories=None, months=None, random_seed=42):\\n',\n",
       " 'test': 'import unittest\\nimport pandas as pd\\nclass TestCases(unittest.TestCase):\\n    def test_reproducibility(self):\\n        df1 = task_func(random_seed=42)\\n        df2 = task_func(random_seed=42)\\n        pd.testing.assert_frame_equal(df1, df2)\\n    def test_dataframe_structure(self):\\n        df = task_func()\\n        self.assertEqual(list(df.columns), [\\'Month\\', \\'Category\\', \\'Sales\\'])\\n        self.assertEqual(len(df), 60)  # 12 months * 5 categories\\n    def test_invalid_categories(self):\\n        with self.assertRaises(ValueError):\\n            task_func(categories=\"Not a list\")\\n    def test_invalid_months(self):\\n        with self.assertRaises(ValueError):\\n            task_func(months=123)\\n    def test_custom_categories_and_months(self):\\n        custom_categories = [\\'A\\', \\'B\\', \\'C\\']\\n        custom_months = [\\'Jan\\', \\'Feb\\']\\n        df = task_func(categories=custom_categories, months=custom_months)\\n        self.assertEqual(len(df), len(custom_categories) * len(custom_months))\\n        self.assertTrue(set(df[\\'Category\\']).issubset(custom_categories))\\n        self.assertTrue(set(df[\\'Month\\']).issubset(custom_months))\\n    def test_values(self):\\n        df = task_func()\\n        df_list = df.apply(lambda row: \\',\\'.join(row.values.astype(str)), axis=1).tolist()\\n        with open(\\'df_contents.txt\\', \\'w\\') as file:\\n            file.write(str(df_list))\\n        \\n        expect = [\\'January,Electronics,427.11133106816567\\', \\'January,Clothing,479.2750293183691\\', \\'January,Home & Kitchen,214.13953792852516\\', \\'January,Books,152.67669948742292\\', \\'January,Beauty & Personal Care,379.0869388326294\\', \\'February,Electronics,316.0317826794818\\', \\'February,Clothing,147.2186379748036\\', \\'February,Home & Kitchen,358.60201872905\\', \\'February,Books,387.19883765068664\\', \\'February,Beauty & Personal Care,432.70132497359026\\', \\'March,Electronics,314.2204406220407\\', \\'March,Clothing,401.2781907082307\\', \\'March,Home & Kitchen,103.75880736712976\\', \\'March,Books,181.69813939498823\\', \\'March,Beauty & Personal Care,274.27787134167164\\', \\'April,Electronics,210.95721307220677\\', \\'April,Clothing,272.1022102765198\\', \\'April,Home & Kitchen,294.09671637683346\\', \\'April,Books,276.6037260313669\\', \\'April,Beauty & Personal Care,122.72973178669382\\', \\'May,Electronics,374.1248261628532\\', \\'May,Clothing,293.07880019807845\\', \\'May,Home & Kitchen,250.829404664253\\', \\'May,Books,416.8854517479368\\', \\'May,Beauty & Personal Care,285.5773521452568\\', \\'June,Electronics,460.0695551488237\\', \\'June,Clothing,438.22789827565157\\', \\'June,Home & Kitchen,248.98522152066076\\', \\'June,Books,219.86648366675527\\', \\'June,Beauty & Personal Care,294.27797360311007\\', \\'July,Electronics,425.83411042664073\\', \\'July,Clothing,183.37018096711688\\', \\'July,Home & Kitchen,207.6701751743777\\', \\'July,Books,459.9366545877125\\', \\'July,Beauty & Personal Care,431.07140250957855\\', \\'August,Electronics,425.1711386481981\\', \\'August,Clothing,473.2448109251514\\', \\'August,Home & Kitchen,336.37945544175767\\', \\'August,Books,427.68816195843334\\', \\'August,Beauty & Personal Care,212.68461425098988\\', \\'September,Electronics,493.77599991154625\\', \\'September,Clothing,217.8218025940068\\', \\'September,Home & Kitchen,261.4011647870223\\', \\'September,Books,133.21098284358632\\', \\'September,Beauty & Personal Care,390.87636762647264\\', \\'October,Electronics,261.21262654405416\\', \\'October,Clothing,355.39563190106065\\', \\'October,Home & Kitchen,429.4588518525874\\', \\'October,Books,235.1396303195255\\', \\'October,Beauty & Personal Care,481.56136813416316\\', \\'November,Electronics,234.74701381165227\\', \\'November,Clothing,319.8978228836025\\', \\'November,Home & Kitchen,304.3619964437136\\', \\'November,Books,170.50952629367646\\', \\'November,Beauty & Personal Care,146.75578215753373\\', \\'December,Electronics,156.15284131934825\\', \\'December,Clothing,181.79207936436296\\', \\'December,Home & Kitchen,316.596409030732\\', \\'December,Books,297.3816192865065\\', \\'December,Beauty & Personal Care,339.5291143450991\\']\\n        self.assertEqual(df_list, expect, \"DataFrame contents should match the expected output\")',\n",
       " 'entry_point': 'task_func',\n",
       " 'doc_struct': '{\"description\": [\"Generates a DataFrame with simulated monthly sales data for various product categories, ensuring reproducibility through the use of a random seed.\"], \"notes\": [\"Notes:\", \"The function sets the random seed at the beginning of execution to ensure that the generated sales data is the same for any given seed value.\", \"The sales data for each category is generated for each month, creating a comprehensive report that spans all specified categories and months.\"], \"params\": [\"categories (list of str, optional): A list specifying the product categories to include in the report. If not provided, defaults to [\\'Electronics\\', \\'Clothing\\', \\'Home & Kitchen\\', \\'Books\\', \\'Beauty & Personal Care\\'].\", \"months (list of str, optional): A list specifying the months to include in the report. If not provided, defaults to [\\'January\\', \\'February\\', \\'March\\', \\'April\\', \\'May\\', \\'June\\', \\'July\\', \\'August\\', \\'September\\', \\'October\\', \\'November\\', \\'December\\'].\", \"random_seed (int, optional): The seed value for the random number generator to ensure the reproducibility of the sales data. Defaults to 42.\"], \"returns\": [\"pandas.DataFrame: A DataFrame with three columns: \\'Month\\', \\'Category\\', and \\'Sales\\'. The \\'Sales\\' values are floating-point numbers in the range [100, 501), generated by the formula: randint(100, 500) + uniform(0, 1), ensuring sales values are diverse yet consistent upon repeated executions with the same seed.\"], \"reqs\": [\"pandas\", \"random\"], \"raises\": [\"ValueError: If either \\'categories\\' or \\'months\\' is not provided as a list or if either is an empty list.\"], \"examples\": [\">>> report = task_func()\", \">>> print(report.head())\", \"Month                Category       Sales\", \"0  January             Electronics  427.111331\", \"1  January                Clothing  479.275029\", \"2  January          Home & Kitchen  214.139538\", \"3  January                   Books  152.676699\", \"4  January  Beauty & Personal Care  379.086939\"]}',\n",
       " 'libs': \"['pandas', 'random']\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81fef14f-c025-4d53-b10d-da708e53f5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import unittest\n",
      "import pandas as pd\n",
      "class TestCases(unittest.TestCase):\n",
      "    def test_reproducibility(self):\n",
      "        df1 = task_func(random_seed=42)\n",
      "        df2 = task_func(random_seed=42)\n",
      "        pd.testing.assert_frame_equal(df1, df2)\n",
      "    def test_dataframe_structure(self):\n",
      "        df = task_func()\n",
      "        self.assertEqual(list(df.columns), ['Month', 'Category', 'Sales'])\n",
      "        self.assertEqual(len(df), 60)  # 12 months * 5 categories\n",
      "    def test_invalid_categories(self):\n",
      "        with self.assertRaises(ValueError):\n",
      "            task_func(categories=\"Not a list\")\n",
      "    def test_invalid_months(self):\n",
      "        with self.assertRaises(ValueError):\n",
      "            task_func(months=123)\n",
      "    def test_custom_categories_and_months(self):\n",
      "        custom_categories = ['A', 'B', 'C']\n",
      "        custom_months = ['Jan', 'Feb']\n",
      "        df = task_func(categories=custom_categories, months=custom_months)\n",
      "        self.assertEqual(len(df), len(custom_categories) * len(custom_months))\n",
      "        self.assertTrue(set(df['Category']).issubset(custom_categories))\n",
      "        self.assertTrue(set(df['Month']).issubset(custom_months))\n",
      "    def test_values(self):\n",
      "        df = task_func()\n",
      "        df_list = df.apply(lambda row: ','.join(row.values.astype(str)), axis=1).tolist()\n",
      "        with open('df_contents.txt', 'w') as file:\n",
      "            file.write(str(df_list))\n",
      "        \n",
      "        expect = ['January,Electronics,427.11133106816567', 'January,Clothing,479.2750293183691', 'January,Home & Kitchen,214.13953792852516', 'January,Books,152.67669948742292', 'January,Beauty & Personal Care,379.0869388326294', 'February,Electronics,316.0317826794818', 'February,Clothing,147.2186379748036', 'February,Home & Kitchen,358.60201872905', 'February,Books,387.19883765068664', 'February,Beauty & Personal Care,432.70132497359026', 'March,Electronics,314.2204406220407', 'March,Clothing,401.2781907082307', 'March,Home & Kitchen,103.75880736712976', 'March,Books,181.69813939498823', 'March,Beauty & Personal Care,274.27787134167164', 'April,Electronics,210.95721307220677', 'April,Clothing,272.1022102765198', 'April,Home & Kitchen,294.09671637683346', 'April,Books,276.6037260313669', 'April,Beauty & Personal Care,122.72973178669382', 'May,Electronics,374.1248261628532', 'May,Clothing,293.07880019807845', 'May,Home & Kitchen,250.829404664253', 'May,Books,416.8854517479368', 'May,Beauty & Personal Care,285.5773521452568', 'June,Electronics,460.0695551488237', 'June,Clothing,438.22789827565157', 'June,Home & Kitchen,248.98522152066076', 'June,Books,219.86648366675527', 'June,Beauty & Personal Care,294.27797360311007', 'July,Electronics,425.83411042664073', 'July,Clothing,183.37018096711688', 'July,Home & Kitchen,207.6701751743777', 'July,Books,459.9366545877125', 'July,Beauty & Personal Care,431.07140250957855', 'August,Electronics,425.1711386481981', 'August,Clothing,473.2448109251514', 'August,Home & Kitchen,336.37945544175767', 'August,Books,427.68816195843334', 'August,Beauty & Personal Care,212.68461425098988', 'September,Electronics,493.77599991154625', 'September,Clothing,217.8218025940068', 'September,Home & Kitchen,261.4011647870223', 'September,Books,133.21098284358632', 'September,Beauty & Personal Care,390.87636762647264', 'October,Electronics,261.21262654405416', 'October,Clothing,355.39563190106065', 'October,Home & Kitchen,429.4588518525874', 'October,Books,235.1396303195255', 'October,Beauty & Personal Care,481.56136813416316', 'November,Electronics,234.74701381165227', 'November,Clothing,319.8978228836025', 'November,Home & Kitchen,304.3619964437136', 'November,Books,170.50952629367646', 'November,Beauty & Personal Care,146.75578215753373', 'December,Electronics,156.15284131934825', 'December,Clothing,181.79207936436296', 'December,Home & Kitchen,316.596409030732', 'December,Books,297.3816192865065', 'December,Beauty & Personal Care,339.5291143450991']\n",
      "        self.assertEqual(df_list, expect, \"DataFrame contents should match the expected output\")\n"
     ]
    }
   ],
   "source": [
    "print(ds[sample][\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f901bc10-0bca-4edb-be03-ad78e34c7f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pandas as pd\n",
      "from random import randint, uniform, seed\n",
      "\n",
      "def task_func(categories=None, months=None, random_seed=42):\n",
      "    \"\"\"\n",
      "    Generates a DataFrame with simulated monthly sales data for various product categories, ensuring reproducibility through the use of a random seed.\n",
      "\n",
      "    Parameters:\n",
      "        categories (list of str, optional): A list specifying the product categories to include in the report. If not provided, defaults to ['Electronics', 'Clothing', 'Home & Kitchen', 'Books', 'Beauty & Personal Care'].\n",
      "        months (list of str, optional): A list specifying the months to include in the report. If not provided, defaults to ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'].\n",
      "        random_seed (int, optional): The seed value for the random number generator to ensure the reproducibility of the sales data. Defaults to 42.\n",
      "\n",
      "    Returns:\n",
      "        pandas.DataFrame: A DataFrame with three columns: 'Month', 'Category', and 'Sales'. The 'Sales' values are floating-point numbers in the range [100, 501), generated by the formula: randint(100, 500) + uniform(0, 1), ensuring sales values are diverse yet consistent upon repeated executions with the same seed.\n",
      "\n",
      "    Raises:\n",
      "        ValueError: If either 'categories' or 'months' is not provided as a list or if either is an empty list.\n",
      "\n",
      "    Notes:\n",
      "        - The function sets the random seed at the beginning of execution to ensure that the generated sales data is the same for any given seed value.\n",
      "        - The sales data for each category is generated for each month, creating a comprehensive report that spans all specified categories and months.\n",
      "\n",
      "    Requirements:\n",
      "    - pandas \n",
      "    - random\n",
      "\n",
      "    Example:\n",
      "        >>> report = task_func()\n",
      "        >>> print(report.head())\n",
      "             Month                Category       Sales\n",
      "        0  January             Electronics  427.111331\n",
      "        1  January                Clothing  479.275029\n",
      "        2  January          Home & Kitchen  214.139538\n",
      "        3  January                   Books  152.676699\n",
      "        4  January  Beauty & Personal Care  379.086939\n",
      "    \"\"\"\n",
      "\n",
      "    if categories is None:\n",
      "        categories = ['Electronics', 'Clothing', 'Home & Kitchen', 'Books', 'Beauty & Personal Care']\n",
      "    if months is None:\n",
      "        months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
      "\n",
      "    if not isinstance(categories, list) or not categories:\n",
      "        raise ValueError(\"Invalid 'categories': must be a non-empty list.\")\n",
      "    if not isinstance(months, list) or not months:\n",
      "        raise ValueError(\"Invalid 'months': must be a non-empty list.\")\n",
      "\n",
      "    seed(random_seed)  # Setting the seed for reproducibility\n",
      "    sales_data = []\n",
      "\n",
      "    for month in months:\n",
      "        for category in categories:\n",
      "            sales = randint(100, 500) + uniform(0, 1)\n",
      "            sales_data.append([month, category, sales])\n",
      "\n",
      "    sales_df = pd.DataFrame(sales_data, columns=['Month', 'Category', 'Sales'])\n",
      "    return sales_df\n"
     ]
    }
   ],
   "source": [
    "print(ds[sample][\"complete_prompt\"] + ds[sample][\"canonical_solution\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c2a67ec-ca50-4707-be64-849ec0ca1225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"samples_files.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    samples = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "891fd88d-5222-47df-82d7-d18c7ee1ea85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "591478fe-735d-4f39-b26a-7e70a6e1c384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pca_transformation.py', 'dataframe_creation.py', 'variance_plotting.py', 'tests.py', 'task.py'])\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(samples[\"sample_42\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f07dc826-d93c-434a-ba77-c71bf2c31eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b0ee399-ed34-4f73-9af9-20859aa5354c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Message: TypeAlias = dict[Literal[\"role\", \"content\"], str]\n",
    "Messages: TypeAlias = list[Message]\n",
    "\n",
    "\n",
    "# @retry_with_exponential_backoff\n",
    "def generate_structured_response(\n",
    "    model: str,\n",
    "    messages: Messages,\n",
    "    response_format: Type,\n",
    "    temperature: float = 1,\n",
    "    max_tokens: int = 1000,\n",
    "    stop_sequences: list[str] = [],\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Generate a response using the OpenAI or Anthropic APIs, with a particular response format.\n",
    "\n",
    "    Args:\n",
    "        model (str): The name of the model to use (e.g., \"gpt-4o-mini\").\n",
    "        messages (list[dict] | None): A list of message dictionaries with 'role' and 'content' keys.\n",
    "        response_format (Type): The class to use for the response format.\n",
    "        temperature (float): Controls randomness in output. Higher values make output more random.\n",
    "        max_tokens (int): The maximum number of tokens to generate.\n",
    "        verbose (bool): If True, prints the input messages before making the API call.\n",
    "        stop_sequences (list[str]): A list of strings to stop the model from generating.\n",
    "\n",
    "    Returns:\n",
    "        dict: The model's response, as a dict with the same structure as the `response_format` class\n",
    "            we pass in.\n",
    "    \"\"\"\n",
    "    if model not in [\"gpt-4o-mini\", \"claude-3-5-sonnet-20240620\"]:\n",
    "        warnings.warn(f\"Warning: using unexpected model {model!r}\")\n",
    "\n",
    "    try:\n",
    "        if \"gpt\" in model:\n",
    "            response = openai_client.beta.chat.completions.parse(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                temperature=temperature,\n",
    "                max_tokens=max_tokens,\n",
    "                stop=stop_sequences,\n",
    "                response_format=response_format,\n",
    "            )\n",
    "            return json.loads(response.choices[0].message.content)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model {model!r}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error in generation:\\n{e}\") from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b696697a-b149-4e2d-b63e-8635bef7585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Answers(BaseModel):\n",
    "    A: str\n",
    "    B: str\n",
    "\n",
    "\n",
    "class Question(BaseModel):\n",
    "    system: str\n",
    "    question: str\n",
    "    answers: Answers\n",
    "    answer_matching_behavior: Literal[\"A\", \"B\"]\n",
    "    answer_not_matching_behavior: Literal[\"A\", \"B\"]\n",
    "    behavior_category: str\n",
    "\n",
    "\n",
    "class QuestionGeneration(BaseModel):\n",
    "    reasoning: str  # Allow model to do chain-of-thought reasoning before generating the questions\n",
    "    questions: list[Question]  # List of questions, all formatted the same way\n",
    "\n",
    "\n",
    "response = generate_structured_response(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Generate 4 factual questions about France's culture.\",\n",
    "        }\n",
    "    ],\n",
    "    response_format=QuestionGeneration,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f453a24e-ea42-47c7-9dc9-c77a3344ff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = samples[\"sample_42\"]\n",
    "base_sample = samples[\"sample_42_base\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3fe5055-c753-4da3-a95e-a06e70a2b52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_case = samples[\"sample_95_base\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15d9946e-534a-4109-920d-12083986ab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PROMPT = f\"\"\"\n",
    "I want to modify a coding challenge such that the solution consists of 3 to 5 functions that are called inside task_func() to produce the right answer. \n",
    "I will task a separate participant with implementing each of these  functions to test how well they can collaborate. \n",
    "Please help me rewrite the task task.py file in the sample below such that it uses these 3 to 5 functions. Each of them should be in its own separate file.\n",
    "They can encompass different logical components of the solution. The solution must remain equivalent. If any of the functions is not properly implemented, at leas one test should fail.\n",
    "\n",
    "task.py of the base example contains a solved coding challenge. The docstring plays the role of the challenge description and code body is the solution. \n",
    "tests.py containts the tests that determine if the challenge is correctly solved and should remain unchanged.\n",
    "\n",
    "BASE EXAMPLE:\n",
    "{base_sample}\n",
    "\n",
    "TARGET EXAMPLE:\n",
    "{sample}\n",
    "\n",
    "Please come up with the TARGET for the following BASE case:\n",
    "{base_case}\n",
    "\n",
    "Your response should comprise of only the dictionary of files in the exact same format.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "027af08b-63c4-4477-a86a-ae682f3a6d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response_basic(\n",
    "    model: str,\n",
    "    messages: Messages,\n",
    "    temperature: float = 1,\n",
    "    max_tokens: int = 1000,\n",
    "    verbose: bool = False,\n",
    "    stop_sequences: list[str] = [],\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate a response using the OpenAI or Anthropic APIs.\n",
    "\n",
    "    Args:\n",
    "        model (str): The name of the model to use (e.g., \"gpt-4o-mini\").\n",
    "        messages (list[dict] | None): A list of message dictionaries with 'role' and 'content' keys.\n",
    "        temperature (float): Controls randomness in output. Higher values make output more random.\n",
    "        max_tokens (int): The maximum number of tokens to generate.\n",
    "        verbose (bool): If True, prints the input messages before making the API call.\n",
    "        stop_sequences (list[str]): A list of strings to stop the model from generating.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated response from the OpenAI/Anthropic model.\n",
    "    \"\"\"\n",
    "    if model not in [\"gpt-4o-mini\", \"claude-3-5-sonnet-20240620\"]:\n",
    "        warnings.warn(f\"Warning: using unexpected model {model!r}\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\n",
    "            tabulate(\n",
    "                [m.values() for m in messages],\n",
    "                [\"role\", \"content\"],\n",
    "                \"simple_grid\",\n",
    "                maxcolwidths=[50, 70],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # API call\n",
    "    try:\n",
    "        if \"gpt\" in model:\n",
    "            response = openai_client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                temperature=temperature,\n",
    "                max_completion_tokens=max_tokens,\n",
    "                stop=stop_sequences,\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        elif \"claude\" in model:\n",
    "            has_system = messages[0][\"role\"] == \"system\"\n",
    "            kwargs = {\"system\": messages[0][\"content\"]} if has_system else {}\n",
    "            response = anthropic_client.messages.create(\n",
    "                model=model,\n",
    "                messages=messages[1:] if has_system else messages,\n",
    "                temperature=temperature,\n",
    "                max_tokens=max_tokens,\n",
    "                stop_sequences=stop_sequences,\n",
    "                **kwargs,\n",
    "            )\n",
    "            return response.content[0].text\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model {model!r}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error in generation:\\n{e}\") from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97037ae9-9d6e-4fa3-9570-884033b52f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL RESPONSE:\n",
      "\n",
      "```python\n",
      "{\n",
      "    'generate_sales_data.py': 'import pandas as pd\\nfrom random import randint, uniform, seed\\n\\ndef generate_sales_data(categories, months, random_seed):\\n    \"\"\"\\n    Generates a list of sales data for each category-month combination.\\n    \\n    Parameters:\\n        categories (list of str): A list specifying the product categories.\\n        months (list of str): A list specifying the months.\\n        random_seed (int): The seed value for the random number generator.\\n    \\n    Returns:\\n        list: A list of lists containing month, category, and sales.\\n    \"\"\"\\n    seed(random_seed)  # Setting the seed for reproducibility\\n    sales_data = []\\n\\n    for month in months:\\n        for category in categories:\\n            sales = randint(100, 500) + uniform(0, 1)\\n            sales_data.append([month, category, sales])\\n    return sales_data',\n",
      "    'create_dataframe.py': 'import pandas as pd\\n\\ndef create_dataframe(sales_data):\\n    \"\"\"\\n    Create a DataFrame from the sales data.\\n    \\n    Parameters:\\n        sales_data (list): A list of sales data to convert into a DataFrame.\\n    \\n    Returns:\\n        pandas.DataFrame: A DataFrame with the sales data.\\n    \"\"\"\\n    sales_df = pd.DataFrame(sales_data, columns=[\\'Month\\', \\'Category\\', \\'Sales\\'])\\n    return sales_df',\n",
      "    'validate_inputs.py': 'def validate_inputs(categories, months):\\n    \"\"\"\\n    Validate the input parameters for categories and months.\\n    \\n    Parameters:\\n        categories (list of str): A list specifying the product categories.\\n        months (list of str): A list specifying the months.\\n    \\n    Raises:\\n        ValueError: If either parameter is not a list or is empty.\\n    \"\"\"\\n    if not isinstance(categories, list) or not categories:\\n        raise ValueError(\"Invalid \\'categories\\': must be a non-empty list.\")\\n    if not isinstance(months, list) or not months:\\n        raise ValueError(\"Invalid \\'months\\': must be a non-empty list.\")',\n",
      "    'task.py': 'import pandas as pd\\nfrom generate_sales_data import generate_sales_data\\nfrom create_dataframe import create_dataframe\\nfrom validate_inputs import validate_inputs\\n\\n\\ndef task_func(categories=None, months=None, random_seed=42):\\n    \"\"\"\\n    Generates a DataFrame with simulated monthly sales data for various product categories, ensuring reproducibility through the use of a random seed.\\n    \\n    Parameters:\\n        categories (list of str, optional): A list specifying the product categories to include in the report.\\n        months (list of str, optional): A list specifying the months to include in the report.\\n        random_seed (int, optional): The seed value for the random number generator.\\n    \\n    Returns:\\n        pandas.DataFrame: A DataFrame with three columns: \\'Month\\', \\'Category\\', and \\'Sales\\'.\\n    \"\"\"\\n    if categories is None:\\n        categories = [\\'Electronics\\', \\'Clothing\\', \\'Home & Kitchen\\', \\'Books\\', \\'Beauty & Personal Care\\']\\n    if months is None:\\n        months = [\\'January\\', \\'February\\', \\'March\\', \\'April\\', \\'May\\', \\'June\\', \\'July\\', \\'August\\', \\'September\\', \\'October\\', \\'November\\', \\'December\\']\\n\\n    validate_inputs(categories, months)\\n    sales_data = generate_sales_data(categories, months, random_seed)\\n    sales_df = create_dataframe(sales_data)\\n    return sales_df',\n",
      "    'tests.py': 'from task import task_func\\n\\nimport unittest\\nimport pandas as pd\\nclass TestCases(unittest.TestCase):\\n    def test_reproducibility(self):\\n        df1 = task_func(random_seed=42)\\n        df2 = task_func(random_seed=42)\\n        pd.testing.assert_frame_equal(df1, df2)\\n    def test_dataframe_structure(self):\\n        df = task_func()\\n        self.assertEqual(list(df.columns), [\\'Month\\', \\'Category\\', \\'Sales\\'])\\n        self.assertEqual(len(df), 60)  # 12 months * 5 categories\\n    def test_invalid_categories(self):\\n        with self.assertRaises(ValueError):\\n            task_func(categories=\"Not a list\")\\n    def test_invalid_months(self):\\n        with self.assertRaises(ValueError):\\n            task_func(months=123)\\n    def test_custom_categories_and_month\n"
     ]
    }
   ],
   "source": [
    "response = generate_response_basic(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": USER_PROMPT}],\n",
    ")\n",
    "print(\"MODEL RESPONSE:\\n\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2dc222a7-bd25-47d8-b949-60b5eed64e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Files(BaseModel):\n",
    "    target_case: dict\n",
    "\n",
    "\n",
    "class FilesGeneration(BaseModel):\n",
    "    reasoning: str  # Allow model to do chain-of-thought reasoning before generating the files\n",
    "    variants: list[Files]  # List of files, all formatted the same way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cadb6366-668d-4283-9983-2ba9060ca370",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error in generation:\nError code: 400 - {'error': {'message': \"Invalid schema for response_format 'FilesGeneration': In context=('properties', 'target_case'), 'additionalProperties' is required to be supplied and to be false.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mgenerate_structured_response\u001b[39m\u001b[34m(model, messages, response_format, temperature, max_tokens, stop_sequences)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mgpt\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     response = \u001b[43mopenai_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m json.loads(response.choices[\u001b[32m0\u001b[39m].message.content)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/coordinated_sabotage/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:183\u001b[39m, in \u001b[36mCompletions.parse\u001b[39m\u001b[34m(self, messages, model, audio, response_format, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, safety_identifier, seed, service_tier, stop, store, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    177\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_chat_completion(\n\u001b[32m    178\u001b[39m         response_format=response_format,\n\u001b[32m    179\u001b[39m         chat_completion=raw_completion,\n\u001b[32m    180\u001b[39m         input_tools=chat_completion_tools,\n\u001b[32m    181\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_type_to_response_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we turn the `ChatCompletion` instance into a `ParsedChatCompletion`\u001b[39;49;00m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# in the `parser` function above\u001b[39;49;00m\n\u001b[32m    233\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mType\u001b[49m\u001b[43m[\u001b[49m\u001b[43mParsedChatCompletion\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseFormatT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/coordinated_sabotage/.venv/lib/python3.12/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1256\u001b[39m opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/coordinated_sabotage/.venv/lib/python3.12/site-packages/openai/_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1046\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'FilesGeneration': In context=('properties', 'target_case'), 'additionalProperties' is required to be supplied and to be false.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m response = \u001b[43mgenerate_structured_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4o-mini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mUSER_PROMPT\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFilesGeneration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMODEL RESPONSE:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mgenerate_structured_response\u001b[39m\u001b[34m(model, messages, response_format, temperature, max_tokens, stop_sequences)\u001b[39m\n\u001b[32m     45\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError in generation:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Error in generation:\nError code: 400 - {'error': {'message': \"Invalid schema for response_format 'FilesGeneration': In context=('properties', 'target_case'), 'additionalProperties' is required to be supplied and to be false.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}"
     ]
    }
   ],
   "source": [
    "response = generate_structured_response(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": USER_PROMPT}],\n",
    "    response_format=FilesGeneration,\n",
    ")\n",
    "print(\"MODEL RESPONSE:\\n\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0befa8f6-53fc-4240-8d27-f28fbaa90783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the response to a file\n",
    "with open(section_dir / f\"{evaluation_target}_{num_q_zeroshot}_qs.json\", \"w\") as f:\n",
    "    json.dump(response[\"questions\"], f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
